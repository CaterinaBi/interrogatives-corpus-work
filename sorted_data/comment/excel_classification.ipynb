{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is to classify the selected examples automatically for those criteria that allow automatic classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import re\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens the excel sheet and reads it\n",
    "# excel sheet needs to be in the same working directory as this file\n",
    "# requires installation of xlrd >= 1.0.0 for Excel support (conversion to .xlsx required by openpyxl)\n",
    "\n",
    "file = 'selected_rows_sorted.xls'\n",
    "data = pd.ExcelFile(file)\n",
    "\n",
    " # returns the all the sheet names within the excel file\n",
    "print(data.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses the sheet into a data frame to show the column structure within the file\n",
    "\n",
    "data_frame = data.parse('Sheet1')\n",
    "data_frame.info\n",
    "\n",
    "# only shows the first 10 rows\n",
    "data_frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in the spreadsheet data\n",
    "\n",
    "workbook = xlrd.open_workbook('selected_rows_sorted.xls')\n",
    "sheet = workbook.sheet_by_name('Sheet1')\n",
    "\n",
    "# gets the first sheet\n",
    "sheet_1 = workbook.sheet_by_index(0)\n",
    "\n",
    "row_count = sheet.nrows\n",
    "col_count = sheet.ncols\n",
    "print(f'Total rows: {row_count}\\nTotal columns: {col_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to create a new list of lists out of the file, and populate the empty columns with as much data as possible.\n",
    "\n",
    "The data that should be easy to classify automatically are: est-ce que / wh- at the beginning or end of sentence / presence of c'est."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialises list of lists\n",
    "all_rows = []\n",
    "\n",
    "for rx in range(sheet.nrows): # rx is an int, row is a list \n",
    "    row = sheet.row(rx)\n",
    "\n",
    "    # initialises list that will contain our data\n",
    "    data_list = []\n",
    "\n",
    "    # populates list that stores all rows\n",
    "    data_list.append(row[0].value)\n",
    "    data_list.append(row[1].value)\n",
    "    data_list.append(row[2].value) # wh\n",
    "    data_list.append(row[3].value) # int\n",
    "    data_list.append(row[4].value) # other\n",
    "    data_list.append(row[5].value) # segment\n",
    "    data_list.append(row[6].value)\n",
    "    data_list.append(row[7].value)\n",
    "    data_list.append(row[8].value)\n",
    "    data_list.append(row[9].value)\n",
    "    data_list.append(row[10].value)\n",
    "    data_list.append(row[11].value)\n",
    "    data_list.append(row[12].value)\n",
    "\n",
    "    all_rows.append(data_list)\n",
    "    # print(all_rows)\n",
    "    \n",
    "# prints extracted rows\n",
    "print(f'We created a list that embeds {len(all_rows)} lists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterates through list of lists and populates empty cells\n",
    "\n",
    "wh = 'comment'\n",
    "string = \"est-ce\"\n",
    "string_count = 0\n",
    "string2 = 'c\\'est'\n",
    "string2_count = 0\n",
    "\n",
    "ex_situ_count = 0\n",
    "in_situ_count = 0\n",
    "fragment_count = 0\n",
    "sv_count = 0\n",
    "\n",
    "for list in all_rows:\n",
    "    text = list[5] # index 5 is where text of interest is stored, returns a cell\n",
    "\n",
    "    if search(string, text):\n",
    "        list[2] = 'ex situ'\n",
    "        list[3] = 'est-ce que'\n",
    "        string_count += 1\n",
    "    elif search(string2, text):\n",
    "        list[3] = 'cleft'\n",
    "        string2_count += 1\n",
    "\n",
    "    if re.search('^comment\\s', text, flags=0):\n",
    "        list[2] = 'ex situ'\n",
    "        ex_situ_count += 1\n",
    "\n",
    "        if search(string2, text):\n",
    "            list[3] = 'cleft'\n",
    "        elif text.endswith('comment ?') or text.endswith('comment Ã§a ?'):\n",
    "            list[2] = 'wh'\n",
    "            list[3] = 'none'\n",
    "            list[4] = 'fragment'\n",
    "            fragment_count += 1\n",
    "        elif re.search('^comment\\sje', text, flags=0) or re.search('^comment\\stu', text, flags=0) or re.search('^comment\\selle', text, flags=0) or re.search('^comment\\sil', text, flags=0) or re.search('^comment\\snous', text, flags=0) or re.search('^comment\\svous', text, flags=0) or re.search('^comment\\selles', text, flags=0) or re.search('^comment\\sils', text, flags=0):\n",
    "            list[3] = 'SV'\n",
    "            sv_count += 1\n",
    "\n",
    "    elif text.endswith('comment ?'):\n",
    "        list[2] = 'in situ'\n",
    "        list[3] = 'SV'\n",
    "        list[4] = 'final'\n",
    "        in_situ_count += 1\n",
    "\n",
    "print(f'{string_count} occurrences of \\'est-ce que\\' found.')\n",
    "print(f'{string2_count} occurrences of \\'c\\'est\\' found.')\n",
    "print(f'{ex_situ_count} occurrences of \\'comment\\' ex situ found.')\n",
    "print(f'{in_situ_count} occurrences of \\'comment\\' in situ found.')\n",
    "print(f'{fragment_count} occurrences of fragments found.')\n",
    "print(f'{sv_count} occurrences of SV ordering found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a new .xlsx file with all the classified data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates spreadsheet using each nested list as a row\n",
    "\n",
    "df = pd.DataFrame(data=all_rows)\n",
    "\n",
    "# converts into excel\n",
    "df.to_excel(\"all_rows_classified.xlsx\", index=False)\n",
    "\n",
    "print(\"Dictionary converted into excel...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens the new excel sheet and reads it\n",
    "# I created a .xls copy of the .xlsx file manually otherwise it won't open\n",
    "\n",
    "file2 = 'all_rows_classified.xls'\n",
    "data2 = pd.ExcelFile(file2)\n",
    "\n",
    "# returns the all the sheet names within the excel file\n",
    "print(data2.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses the sheet into a data frame to show the column structure within the file\n",
    "\n",
    "data_frame2 = data2.parse('Sheet1')\n",
    "data_frame2.info\n",
    "\n",
    "# only shows the first 10 rows\n",
    "data_frame2.head(60)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7b2d02c07dc615871e2bd1a1246b89714f2151eeb8e00fcd4ada13785228d85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
